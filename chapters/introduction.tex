\chapter{Introduction}\label{chapter:introduction}

\section{Motivation}


Databases are more in the center of innovation than ever. With the growing demands on storing and analyzing large amounts of data, linked with the capabilities of modern hardware, database vendors and researchers face new challenges and possibilities. 
\\
Traditionally, databases are disk-based systems separated into two parts: One system used for Online Transactional Processing (OLTP), optimized for high rates of mission-critical, transactional write requests. As second system, a data warehouse is used for Online Analytical Processing (OLAP), executing long-running queries to gain insight into the  collected data, used to make future business decisions upon. Due to this contradicting requirements of critical, short write requests on the one side and long running, business-intelligence gaining read requests on the other side, traditionally two separated systems are used. The data synchronization between the two systems is ensured by an ETL process: Data is extracted from the OLTP system, transformed and loaded into the OLAP system. Since this process implicates heavy load on the database, it is usually done periodically, e.g. over night. Obviously, this architecture reveals several drawbacks, like stale data, redundancy and the maintenance cost of two systems.
\\
Modern hardware allows us to move away from this paradigm: Instead of disk-based databases, the data can be stored in memory. Since memory can be accessed much faster than the disk, an unprecedented throughput of OLTP transactions is possible. Using snapshots of the transactional data by exploiting the virtual memory management of the operating system, OLAP queries can run in parallel next to the OLTP transactions on up-to-date data. Such a system is HyPer, a relational main-memory database guaranteeing the ACID properties, actively developed at the Chair of Database Systems at the TU MÃ¼nchen, and the main system used for our research. 
\\
The possibility of executing OLAP queries on a relational DBMS without interfering the OLTP transaction throughput opens new possibilities for database systems. Additionally to long-running OLAP queries, data mining algorithms can be implemented and executed in HyPer. Data mining extends the possibilities of OLAP by applying more compelex algorithms to discover interesting patterns and knowledge from the data. Crucial techniques are mining frequent patterns and association rules, classification, clustering and outlier detection.
\\
Usually data has to be integrated from databases and other data sources by ETL processes, resulting in the same disadvantages as for data warehouses: data is not up-to-date for the crucial analyzing phase and redundant. By implemented data mining algorithms right into the database, data analysts, data scientists and business executives gain huge benefits. 
\\
Instead of bringing the data to the algorithm, the algorithms is brought to the data. No ETL processes are necessary to export data to an additional system for data analysis. Instead, the algorithms can be executed directly on the database system and on up-to-date data. The execution of the algorithms can benefit from the modern hardware and high computation power of a database system. And, the data mining process can be combined with already existing database operators such as grouping and aggregation.


\section{Research Questions}
With more and more data generated by modern IT systems, knowledge discovery and data mining is rapidly growing and data mining software gains a growing amount of attention. So far, most data scientists use standalone data mining tools such as R, Julia or the Python library SciPy. Also the Java frameworks Weka and ELKI are used actively, in particular in the research community. All tools are providing an environement for statistical computing and the application of various data mining algorithms. For mining tera- and petabytes of data, big data software such as Apache Hadoop, Apache Sparx and machine-learning framework Apache Mahout are used.
\\
While all of the presented environments are frequently used by data scientists, they demonstrate one decisive drawback: Before executing data mining algorithms on the datasets, the data first has to be fetched from the database and transformed into a format readable by these tools.
Therefore, tools like MADlib and RapidMiner are trying to fill the gap. Supporting specific database engines, data mining is brought closer to the database. Algorithms can be run on the database, using extensible SQL, already existing SQL operators, stored procedures and the possibility to run high-level "glue" code on the database. These tools provide a middleware between the database and data mining tools, and therefore data export becomes obsolete. 
\\
However, for complex algorithms SQL operators have to be combined by high-level constructs, often resulting in a bad performance. Therefore, database vendors such as Oracle and SAP are providing their databases with more and more statistical and data mining functionalities using existing SQL syntax. This leads to several advantages: A database system provides already efficient data storage and access, therefore data mining algorithms implemented on the database can benefit from these data structures. Besides, databases are optimized for modern hardware, e.g. multicore processors and cache hierarchies, which makes them presumably faster than platform-independent tools. Furthermore, data mining algorithms can profit from database features such as parallelization, scalability, recovery and backup facilities as well as the query language SQL. SQL itself comes already with useful algorithms for data analysis such as selection, sorting and aggregation. Therefore an extension of the query language to integrate other algorithms for data mining would feel very natural to the data scientist. 
\\
Regarding those advantages, our research goal is to extend HyPer with data mining functionalities, exploiting the performance of a database for computational operations and building a general-purpose system for OLTP, OLAP and data mining queries. For a great user experience, a intuitive user interface has to be provided: A functional language, that is easy to understand and avoids side-effects, and plotting options will be included.


\section{Approach}
As proof of concept, the well-known k-Means algorithm will be implemented as a HyPer operator. K-Means is one of the most popular  clustering algorithms and available on all presented platforms. Since the algorithm is relatively simple and straightforward, a good comparability between different tools is given. The main metric for comparing different tools is the performance of algorithms. Since most data mining algorithms are non-deterministic, the time per iteration will be the main criteria. The implementation of k-Means should also demonstrate the possibilities of implementing data mining algorithms in HyPer.
\\
HyPer provides a programming model for the implementation of operators and combines pre-compiled C++ code with dynamically generated LLVM code. Yet, the programmer has a lot of freedom in implementing complex data mining operators. This work compares different implementation aspects of the k-Means algorithm and aims to detect patterns and building blocks for further algorithms.
\\
The remainder of this paper is organized as follows: In the next section, the HyPer database is presented. Next, the term knowledge discovery and data mining is defined. Then, the k-Means operator is introduced and its implementation aspects as HyPer operator are shown. Finally, extensive experiments demonstrate the benefits of k-Means in HyPer .



