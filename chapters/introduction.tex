\chapter{Introduction}\label{chapter:introduction}

Databases are more than ever in the center of innovation. With the growing demands on storing and analyzing large amounts of data, linked with the capabilities of modern hardware, database vendors and researchers face new challenges and possibilities. One of these possibilities is to execute data mining algorithms directly on the database. In this thesis we present an approach to integrate data mining techniques into the main memory database HyPer.

\section{Motivation}

Traditionally, databases are disk-based systems separated into two parts: One system used for Online Transactional Processing (OLTP), optimized for high rates of mission-critical, transactional write requests. As second system, a data warehouse is used for Online Analytical Processing (OLAP), executing long-running queries to gain insight into the  collected data, used to make future decisions upon. Due to these contradicting requirements of critical, short write requests on one side and long running, business-intelligence gaining read requests on the other side, traditionally two separated systems are used. The data synchronization between the two systems is ensured by an Extract-Transform-Load (ETL) process: Data is extracted from the OLTP system, transformed and loaded into the OLAP system. Since this process implicates heavy load on the database, it is usually done periodically, e.g. once a night. Obviously, this architecture reveals several drawbacks, like stale data, redundancy and the maintenance cost of two systems.
\\
Modern hardware allows us to move away from this paradigm: Instead of using disk-based databases the data can be stored in memory. Since memory can be accessed much faster than the disk, an unprecedented throughput of OLTP transactions is possible. Using snapshots of the transactional data by exploiting the virtual memory management of the operating system, OLAP queries can run in parallel next to the OLTP transactions on up-to-date data. Such a system is HyPer~\parencite{5767867}, a relational main memory database guaranteeing the ACID properties. It is actively developed at the Chair of Database Systems at the TU MÃ¼nchen, and the main system used for our research. 
\\
The possibility of executing OLAP queries on a relational DBMS without interfering the OLTP transaction throughput opens new possibilities for database systems: Additionally to long-running OLAP queries, data mining algorithms can be implemented and executed in HyPer. Data mining extends the possibilities of OLAP by applying more complex algorithms to discover interesting patterns and knowledge from the data. Crucial techniques are mining frequent patterns and association rules, classification, clustering and outlier detection.
\\
Usually data mining tools have to import and integrate data from databases and other data sources by ETL processes, resulting in the same disadvantages as for data warehouses: data is not up-to-date for the crucial analyzing phase and redundant. 
By implementing data mining algorithms right into the database, data analysts, data scientists and business executives gain huge benefits. Instead of bringing the data to the algorithm, the algorithms are brought to the data. No ETL processes are necessary to export data to an additional system for data mining. Instead, the algorithms can be executed directly on the database system on up-to-date data. The execution of the algorithms benefits from the modern hardware and high computational power of the database system. Additionally, the data mining process can be combined with already existing database operators such as grouping and aggregation, resulting in a very natural environment for data analysis.


\section{Research Questions}
With more and more data generated by modern IT systems, the needs for analyzing large amounts of data are rapidly growing and data mining software gets an increasing amount of attention. So far, most data scientists use standalone data mining tools such as R~\parencite{R/stats}, Julia~\parencite{DBLP:journals/corr/abs-1209-5145} or the Python ecosystem SciPy~\parencite{scipy}. Furthermore, the Java frameworks Weka~\parencite{Hall:2009:WDM:1656274.1656278} and ELKI~\parencite{DBLP:conf/ssdbm/AchtertKZ08} are used actively, in particular in the research community. All tools are providing an environment for statistical computing and the application of various data mining algorithms. Additionally, for mining tera- and petabytes of data, scalable software such as Apache Hadoop~\parencite{hadoop}, Apache Spark~\parencite{spark} and the data mining and machine learning framework Apache Mahout~\parencite{mahout} are used.
\\
While all of the presented environments are frequently used by data scientists, they demonstrate one decisive drawback: Before executing data mining algorithms, the data first has to be fetched from the database and transformed into a format readable by these tools. Therefore a first enhancement is to bring the algorithms closer to the database. Tools like MADlib~\parencite{MADlib} and RapidMiner~\parencite{rapidminer} are supporting specific database engines and trying to fill this gap. Algorithms can be run on the database, using extensible SQL, already existing SQL operators and stored procedures, often connected with high-level \enquote{glue} code. These tools provide a middleware between the database and data mining software and therefore data export becomes obsolete. 
\\
However, this combination of SQL operators with high-level code is often resulting in bad performance. Therefore, database vendors such as Oracle and SAP are going one step further and providing their databases with more and more statistical and data mining functionalities using the existing SQL syntax and graphical user interfaces~\parencite{oracle}~\parencite{pal}. This leads to several advantages: A database system provides already efficient data storage and access, therefore data mining algorithms implemented on the database can benefit from these data structures. Besides, databases are optimized for modern hardware, e.g. multi core processors and cache hierarchies, which makes them presumably faster than platform-independent tools. Furthermore, data mining algorithms can profit from database features such as parallelization, scalability, recovery and backup facilities as well as from the query language SQL. SQL itself comes already with useful algorithms for data analysis such as selection, sorting and aggregation. Therefore an extension of the query language to integrate other algorithms for data mining would feel very natural to the data scientist. 
\\
Regarding those advantages our research goal is to extend HyPer by data mining functionalities that can be executed directly on the database, exploiting the performance of modern database hardware for computational operations and building a general-purpose system for OLTP, OLAP and data mining queries. This thesis presents a proof-of-concept implementation of data mining in HyPer. It is part of a larger project that goes one step further and will provide an intuitive user interface around the algorithms: A functional language that is easy to learn, avoids side-effects and might provide plotting options. 


\section{Approach}
As proof-of-concept, the well-known k-Means algorithm is implemented as a HyPer operator. K-Means is one of the most popular  clustering algorithms and available on all presented platforms. As the algorithm is relatively simple and straightforward, a good comparability between different tools and their performance is given. Since most data mining algorithms are non-deterministic, the time per iteration will be used as the main performance criterion. An implementation of k-Means will demonstrate the possibilities of implementing and running data mining algorithms on HyPer.
\\
HyPer provides a programming model for the implementation of operators by combining pre-compiled C++ code with dynamically generated LLVM code. Yet, the programmer has a lot of freedom in implementing complex data mining operators. This work compares different implementations of the k-Means algorithm and aims to detect best practices, patterns and building blocks for the implementation of further algorithms.
\\
The remainder of this thesis is organized as follows: In the next section, fundamentals of the HyPer database are presented. In Chapter~\ref{chapter:kdd}, a brief introduction of the terms knowledge discovery and data mining is given. Then, the k-Means clustering algorithm is introduced. Chapter~\ref{chapter:related} discusses other data mining tools and databases with data mining functionalities. In Chapter~\ref{chapter:implementation} the implementation of the k-Means clustering algorithm as HyPer operator is depicted. Chapter~\ref{chapter:evaluation} discusses extensive experiments that demonstrate the applicability of data mining algorithms on HyPer. Chapter~\ref{chapter:conclusion} concludes the thesis.




